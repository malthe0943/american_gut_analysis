{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\malth\\OneDrive - University of Copenhagen\\Bachelor\\programs\\true_preprocessing.py:34: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  X_4 = X_3 / np.sum(X_3, axis=1)[:, np.newaxis]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from functions import *\n",
    "from tqdm import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, r2_score\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import true_preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check specific functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_CV(X, y):\n",
    "    ref_scores = []\n",
    "    for i in range(5):\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "        dummy = DummyRegressor(strategy=\"mean\")\n",
    "        ref_scores.append(np.mean(cross_val_score(dummy, X, y, scoring=scorer, cv=kf)))\n",
    "    return ref_scores\n",
    "\n",
    "def SVM_CV(X, y):\n",
    "    # Define outer cross-validation splits\n",
    "    cv_outer = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    # Create lists to store results\n",
    "    results_params = []; results_scores = []\n",
    "\n",
    "    # Perform nested cross-validation\n",
    "    for train_ix, test_ix in cv_outer.split(X):\n",
    "        # Split data\n",
    "        X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
    "        y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "        \n",
    "        # Configure the inner cross-validation procedure\n",
    "        cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "        \n",
    "        # Define the model and parameters\n",
    "        model = SVR()\n",
    "        parameters = {\"C\": [1, 10, 100], \"gamma\": [.001, .01, .1]}\n",
    "\n",
    "        # Define and do search\n",
    "        search = GridSearchCV(model, parameters, scoring=scorer, cv=cv_inner, refit=True, n_jobs=6)\n",
    "        result = search.fit(X_train, y_train)\n",
    "        \n",
    "        # Get the best performing model fit on the whole training set and evaluate it on the holdout set\n",
    "        best_model = result.best_estimator_\n",
    "        yhat = best_model.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        acc = mean_squared_error(y_test, yhat)\n",
    "        \n",
    "        # Report progress\n",
    "        print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "        #outer_results.append([acc, result.best_score_, result.best_params_])\n",
    "        results_scores.append(acc)\n",
    "        results_params.append(result.best_params_)\n",
    "    return results_scores, results_params\n",
    "\n",
    "    # Summarize the estimated performance of the model\n",
    "    #print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))\n",
    "\n",
    "def logistic_CV(X, y):\n",
    "    # Define outer cross-validation splits\n",
    "    cv_outer = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    # Create lists to store results\n",
    "    results_params = []; results_scores = []\n",
    "    # Perform nested cross-validation\n",
    "    for train_ix, test_ix in cv_outer.split(X):\n",
    "        # Split data\n",
    "        X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
    "        y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "        \n",
    "        # Configure the inner cross-validation procedure\n",
    "        cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "        \n",
    "        # Define the model and parameters\n",
    "        model = Lasso()\n",
    "        parameters = {'alpha':list(np.logspace(-4,2,7,10))}\n",
    "\n",
    "        # Define and do search\n",
    "        search = GridSearchCV(model, parameters, scoring=scorer, cv=cv_inner, refit=True, n_jobs=6)\n",
    "        result = search.fit(X_train, y_train)\n",
    "        \n",
    "        # Get the best performing model fit on the whole training set and evaluate it on the holdout set\n",
    "        best_model = result.best_estimator_\n",
    "        yhat = best_model.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        acc = mean_squared_error(y_test, yhat)\n",
    "        \n",
    "        # Report progress\n",
    "        print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "        results_scores.append(acc)\n",
    "        results_params.append(result.best_params_)\n",
    "    return results_scores, results_params\n",
    "\n",
    "def rf_CV(X, y):\n",
    "    # Define outer cross-validation splits\n",
    "    cv_outer = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    # Create lists to store results\n",
    "    results_params = []; results_scores = []\n",
    "\n",
    "    # Perform nested cross-validation\n",
    "    for train_ix, test_ix in cv_outer.split(X):\n",
    "        # Split data\n",
    "        X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
    "        y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "        \n",
    "        # Configure the inner cross-validation procedure\n",
    "        cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "        \n",
    "        # Define the model and parameters\n",
    "        model = RandomForestRegressor(random_state=1, n_jobs=6)\n",
    "        parameters = {'n_estimators':np.linspace(50,1000,4,True,dtype=int), 'max_features':np.linspace(0.05,0.9,4,True)}\n",
    "\n",
    "        # Define and do search\n",
    "        search = GridSearchCV(model, parameters, scoring=scorer, cv=cv_inner, refit=True, n_jobs=6)\n",
    "        result = search.fit(X_train, y_train)\n",
    "        \n",
    "        # Get the best performing model fit on the whole training set and evaluate it on the holdout set\n",
    "        best_model = result.best_estimator_\n",
    "        yhat = best_model.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        acc = mean_squared_error(y_test, yhat)\n",
    "        \n",
    "        # Report progress\n",
    "        print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "        results_scores.append(acc)\n",
    "        results_params.append(result.best_params_)\n",
    "    return results_scores, results_params\n",
    "\n",
    "def rename_columns(X):\n",
    "    new_columns = [f\"feature_{i}\" for i in range(len(X.columns))]\n",
    "    X.columns = new_columns\n",
    "    return X\n",
    "\n",
    "def XGB_CV(X, y):\n",
    "    #Transform classes to numbers and feature names to feature_0, feature_1 and so on\n",
    "    le = LabelEncoder()\n",
    "    y_XGB = pd.Series(le.fit_transform(y))\n",
    "    X = rename_columns(X)\n",
    "    \n",
    "    # Define outer cross-validation splits\n",
    "    cv_outer = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    # Create lists to store results\n",
    "    results_params = []; results_scores = []\n",
    "\n",
    "    # Perform nested cross-validation\n",
    "    for train_ix, test_ix in cv_outer.split(X):\n",
    "        # Split data\n",
    "        X_train, X_test = X.iloc[train_ix, :], X.iloc[test_ix, :]\n",
    "        y_train, y_test = y_XGB.iloc[train_ix], y_XGB.iloc[test_ix]\n",
    "        \n",
    "        # Configure the inner cross-validation procedure\n",
    "        cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "        \n",
    "        # Define the model and parameters\n",
    "        model = XGBRegressor(colsample_bytree=0.02, reg_lambda=1, objective='multi:softmax')\n",
    "        parameters = {'max_depth': [2, 4, 8],\n",
    "              'learning_rate': [0.5, 0.15, 0.3],\n",
    "              #'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "              #'colsample_bytree': np.arange(0.4, 1.0, 0.2),\n",
    "              #'colsample_bylevel': np.arange(0.4, 1.0, 0.2),\n",
    "              'n_estimators': [100, 500, 1000]}\n",
    "\n",
    "        # Define and do search\n",
    "        search = GridSearchCV(model, parameters, scoring=scorer, cv=cv_inner, refit=True, n_jobs=6)\n",
    "        result = search.fit(X_train, y_train)\n",
    "        \n",
    "        # Get the best performing model fit on the whole training set and evaluate it on the holdout set\n",
    "        best_model = result.best_estimator_\n",
    "        yhat = best_model.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        acc = mean_squared_error(y_test, yhat)\n",
    "        \n",
    "        # Report progress\n",
    "        print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "        results_scores.append(acc)\n",
    "        results_params.append(result.best_params_)\n",
    "    return results_scores, results_params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = pd.read_csv('X_data.csv', low_memory=False)\n",
    "X_data = X_data.rename(columns = {'Unnamed: 0':'id'}) #Changing name of id-column\n",
    "X_data = X_data.loc[:,(X_data != 0).any(axis=0)] #Removing all all-zero columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = pd.read_csv('meta_data.csv', low_memory=False)\n",
    "meta_data = meta_data.rename(columns = {'Unnamed: 0':'id'}) #Changing name of id-column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for column_name in X_data.columns:\n",
    "    column = X_data[column_name]\n",
    "    share = 1-(column == 0).sum()/len(X_data)\n",
    "    if share >= 0.25:\n",
    "        list.append(column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = X_data[list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keeps columns with median of non-zero values bigger than x\n",
    "list = []\n",
    "for column_name in X_1.columns:\n",
    "    if column_name != 'id':\n",
    "        non_zeros = X_1.loc[X_1[column_name] != 0, column_name]\n",
    "        if non_zeros.median() >= 5:\n",
    "            list.append(column_name)\n",
    "    else:\n",
    "        list.append(column_name)\n",
    "X_2 = X_1[list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3 = my_multiplicative_replacement(X_2.iloc[:,1:])\n",
    "X_4 = my_clr(X_3.astype(float))\n",
    "X_5 = pd.concat([pd.DataFrame(X_4),meta_data['bmi'], meta_data['country']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malth\\AppData\\Local\\Temp\\ipykernel_15584\\4153994901.py:6: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_8.iloc[:,-1] = X_8.iloc[:,-1].astype('float')\n"
     ]
    }
   ],
   "source": [
    "X_6 = remove_rows_where_column_nan(X_5,'bmi')\n",
    "X_7 = keep_rows_where_column_specified(X_6,'country','United Kingdom')\n",
    "X_7 = X_7.iloc[:,:280]\n",
    "X_8 = remove_rows_where_column_specified(X_7,'bmi','Unspecified')\n",
    "X_8 = remove_rows_where_column_specified(X_8,'bmi','unknown')\n",
    "X_8.iloc[:,-1] = X_8.iloc[:,-1].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_forest_tester(X_8,meta_data,concat_bool=False,target_column='bmi',condition_column=None,scoring_function='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.52800e+01, 3.67300e+01, 2.45400e+01, 1.97200e+01, 1.86500e+01,\n",
       "       2.97600e+01, 2.19500e+01, 2.39400e+01, 3.41100e+01, 2.67100e+01,\n",
       "       2.19700e+01, 2.89000e+01, 3.81200e+01, 1.92700e+01, 2.43300e+01,\n",
       "       2.91200e+01, 2.92900e+01, 3.19200e+01, 1.86100e+01, 2.56500e+01,\n",
       "       2.56100e+01, 3.35900e+01, 2.35900e+01, 2.47500e+01, 2.20500e+01,\n",
       "       2.26000e+01, 2.42200e+01, 1.94700e+01, 2.68400e+01, 2.67500e+01,\n",
       "       2.10600e+01, 2.00200e+01, 2.26600e+01, 2.10500e+01, 2.26500e+01,\n",
       "       3.01000e+01, 2.43800e+01, 1.28900e+01, 3.75500e+01, 1.75100e+01,\n",
       "       1.96600e+01, 2.70000e-01, 2.26400e+01, 3.86000e+01, 2.67800e+01,\n",
       "       1.96800e+01, 2.49600e+01, 1.88300e+01, 2.10700e+01, 2.66300e+01,\n",
       "       2.44600e+01, 4.23900e+01, 2.53900e+01, 2.39600e+01, 2.02000e+01,\n",
       "       2.23200e+01, 2.97700e+01, 2.78200e+01, 2.04800e+01, 2.31700e+01,\n",
       "       2.31500e+01, 2.57300e+01, 1.60500e+01, 2.64700e+01, 2.65800e+01,\n",
       "       2.47800e+01, 2.35100e+01, 2.36700e+01, 1.81000e+01, 2.09000e+01,\n",
       "       1.90100e+01, 3.03800e+01, 2.35500e+01, 2.48400e+01, 2.20700e+01,\n",
       "       2.31900e+01, 1.56200e+01, 3.40600e+01, 1.91000e+01, 1.59700e+01,\n",
       "       2.00700e+01, 2.02400e+01, 2.52400e+01, 3.39100e+01, 2.53100e+01,\n",
       "       2.18000e+01, 2.02000e+00, 3.22200e+01, 2.45800e+01, 3.18400e+01,\n",
       "       2.28600e+01, 2.62300e+01, 2.00500e+01, 2.61100e+01, 2.30000e-01,\n",
       "       2.07400e+01, 2.59000e+01, 1.63500e+01, 2.78900e+01, 2.07500e+01,\n",
       "       2.13500e+01, 1.50400e+01, 3.33200e+01, 1.88000e+01, 1.90800e+01,\n",
       "       2.71200e+01, 2.98400e+01, 1.72300e+01, 4.17800e+01, 2.05500e+01,\n",
       "       2.13000e+01, 1.95700e+01, 2.19100e+01, 1.57500e+01, 2.03100e+01,\n",
       "       9.03000e+00, 1.99000e+01, 2.30100e+01, 2.17100e+01, 2.72200e+01,\n",
       "       1.10900e+01, 2.43400e+01, 1.45000e+01, 2.41200e+01, 2.34600e+01,\n",
       "       2.82000e+01, 2.05200e+01, 2.15200e+01, 2.27600e+01, 2.28100e+01,\n",
       "       2.59900e+01, 2.44200e+01, 2.74400e+01, 2.21000e+01, 2.70600e+01,\n",
       "       2.40900e+01, 2.32400e+01, 2.82800e+01, 3.15600e+01, 2.69100e+01,\n",
       "       2.83300e+01, 2.05600e+01, 2.36600e+01, 2.18600e+01, 2.66600e+01,\n",
       "       1.97300e+01, 2.83200e+01, 3.01200e+01, 2.42100e+01, 2.55300e+01,\n",
       "       2.22700e+01, 2.85300e+01, 2.66800e+01, 2.09700e+01, 2.07600e+01,\n",
       "       2.72500e+01, 2.01600e+01, 2.98600e+01, 2.36300e+01, 2.74800e+01,\n",
       "       2.11100e+01, 2.17200e+01, 2.28300e+01, 2.27100e+01, 3.36600e+01,\n",
       "       2.44400e+01, 2.95600e+01, 1.95600e+01, 2.13700e+01, 2.74700e+01,\n",
       "       1.50880e+02, 3.36400e+01, 2.44500e+01, 2.00100e+01, 2.15300e+01,\n",
       "       2.63200e+01, 1.90300e+01, 2.72900e+01, 2.83400e+01, 2.06600e+01,\n",
       "       2.29600e+01, 2.08000e+01, 2.05800e+01, 2.12900e+01, 2.86500e+01,\n",
       "       2.30200e+01, 2.37400e+01, 2.10900e+01, 1.94800e+01, 1.98000e+01,\n",
       "       2.11400e+01, 3.07000e+01, 2.40100e+01, 2.11900e+01, 3.12100e+01,\n",
       "       2.73200e+01, 2.11500e+01, 2.48600e+01, 2.75100e+01, 2.41600e+01,\n",
       "       2.41700e+01, 2.80900e+01, 2.63100e+01, 2.03300e+01, 2.46800e+01,\n",
       "       2.56200e+01, 2.68500e+01, 2.70200e+01, 1.83400e+01, 2.36000e+01,\n",
       "       2.43100e+01, 2.48200e+01, 2.09500e+01, 2.60400e+01, 1.79000e+01,\n",
       "       2.14830e+02, 2.04700e+01, 2.00600e+01, 1.52600e+01, 1.99200e+01,\n",
       "       2.09900e+01, 2.53400e+01, 2.59400e+01, 2.92200e+01, 2.17400e+01,\n",
       "       2.24500e+01, 2.91800e+01, 2.61500e+01, 3.25900e+01, 2.08100e+01,\n",
       "       2.71000e+01, 2.17800e+01, 2.16300e+01, 2.57800e+01, 2.34400e+01,\n",
       "       2.41500e+01, 2.58300e+01, 6.24800e+01, 2.07000e+01, 2.49900e+01,\n",
       "       2.49000e+01, 2.25000e+01, 1.73000e+01, 2.14600e+01, 2.40300e+01,\n",
       "       2.20300e+01, 2.06900e+01, 2.78400e+01, 2.28800e+01, 2.55400e+01,\n",
       "       2.33400e+01, 2.44300e+01, 2.62100e+01, 2.02800e+01, 1.93500e+01,\n",
       "       1.70100e+01, 1.87500e+01, 2.44900e+01, 2.80000e-01, 2.24800e+01,\n",
       "       2.70400e+01, 1.37800e+01, 1.81700e+01, 2.59700e+01, 2.34100e+01,\n",
       "       2.68800e+01, 2.23800e+01, 2.09300e+01, 2.30300e+01, 2.11200e+01,\n",
       "       2.52100e+01, 4.44000e+00, 3.19500e+01, 2.27200e+01, 2.42700e+01,\n",
       "       2.20400e+01, 3.95400e+01, 2.12300e+01, 2.09400e+01, 2.65100e+01,\n",
       "       2.90400e+01, 2.31300e+01, 2.03400e+01, 3.08200e+01, 2.79700e+01,\n",
       "       2.08900e+01, 2.27800e+01, 2.73400e+01, 2.63600e+01, 2.46600e+01,\n",
       "       2.29900e+01, 2.41400e+01, 2.39900e+01, 2.34800e+01, 2.24100e+01,\n",
       "       2.48000e+01, 2.33100e+01, 2.50600e+01, 2.14800e+01, 1.98300e+01,\n",
       "       2.64800e+01, 2.47300e+01, 3.22900e+01, 1.36700e+01, 1.98100e+01,\n",
       "       2.67600e+01, 1.73600e+01, 1.14900e+01, 2.50800e+01, 2.06000e+01,\n",
       "       2.02900e+01, 4.58300e+01, 2.23500e+01, 2.06700e+01, 2.01900e+01,\n",
       "       2.87600e+01, 4.01200e+01, 2.51800e+01, 2.52600e+01, 2.61800e+01,\n",
       "       2.94100e+01, 2.36100e+01, 3.37800e+01, 2.05400e+01, 2.30400e+01,\n",
       "       2.63000e+01, 2.94200e+01, 1.97500e+01, 2.16000e+01, 2.25900e+01,\n",
       "       1.84200e+01, 2.22300e+01, 2.44800e+01, 3.95700e+01, 2.44100e+01,\n",
       "       2.81200e+01, 2.98500e+01, 2.11300e+01, 2.10800e+01, 1.88100e+01,\n",
       "       1.75300e+01, 2.01100e+01, 2.00000e+01, 2.49100e+01, 1.79700e+01,\n",
       "       2.75604e+03, 2.84100e+01, 2.25800e+01, 2.64300e+01, 2.25300e+01,\n",
       "       2.34360e+02, 2.83100e+01, 1.85200e+01, 4.25100e+01, 2.58500e+01,\n",
       "       3.18300e+01, 2.35300e+01, 2.19300e+01, 1.79200e+01, 2.13400e+01,\n",
       "       2.33600e+01, 2.02500e+01, 2.21300e+01, 2.05700e+01, 2.50900e+01,\n",
       "       3.93800e+01, 2.51600e+01, 2.01200e+01, 1.82400e+01, 2.22400e+01,\n",
       "       2.62900e+01, 3.71200e+01, 2.21400e+01, 5.84800e+01, 6.25000e+01,\n",
       "       2.51000e+01, 2.34200e+01, 3.57400e+01, 1.94400e+01, 2.80800e+01,\n",
       "       1.91300e+01, 4.03000e+00, 2.81700e+01, 2.60100e+01, 2.22200e+01,\n",
       "       1.92200e+01, 1.60000e+01, 2.76300e+01, 4.35600e+01, 1.91400e+01,\n",
       "       2.04300e+01, 2.69600e+01, 2.79400e+01, 4.13500e+01, 2.92700e+01,\n",
       "       1.97100e+01, 2.09600e+01, 1.95300e+01, 2.16100e+01, 2.85200e+01,\n",
       "       3.17900e+01, 2.08300e+01, 2.27700e+01, 1.77600e+01, 2.05000e+01,\n",
       "       2.45600e+01, 2.77400e+01, 1.83700e+01, 1.93300e+01, 1.81800e+01,\n",
       "       3.43100e+01, 2.12600e+01, 9.63000e+00, 1.74000e+01, 1.99600e+01,\n",
       "       2.87300e+01, 1.98400e+01, 1.99500e+01, 2.60500e+01, 5.22600e+01,\n",
       "       2.68900e+01, 2.42000e+01, 2.37100e+01, 2.03700e+01, 1.84700e+01,\n",
       "       1.89300e+01, 2.76200e+01, 3.12400e+01, 2.58600e+01, 2.79200e+01,\n",
       "       3.40100e+01, 2.86700e+01, 2.23100e+01, 2.77800e+01, 1.98800e+01,\n",
       "       2.33200e+01, 2.20900e+01, 2.64900e+01, 2.37300e+01, 3.87400e+01,\n",
       "       2.32500e+01, 1.91100e+01, 2.03200e+01, 2.57000e+01, 2.57100e+01,\n",
       "       2.49300e+01, 2.22100e+01, 2.56300e+01, 1.90200e+01, 2.40700e+01,\n",
       "       1.71800e+01, 2.94300e+01, 2.43000e+01, 1.90500e+01, 1.76900e+01,\n",
       "       2.27900e+01, 2.87000e+01, 1.66500e+01, 1.96300e+01, 2.85000e+01,\n",
       "       2.33700e+01, 2.20100e+01, 1.41100e+01, 1.30200e+01, 1.24000e+01,\n",
       "       2.32600e+01, 2.56800e+01, 4.19600e+01, 2.62600e+01, 1.97800e+01,\n",
       "       3.16200e+01, 2.26700e+01, 2.98100e+01, 2.47400e+01, 1.93900e+01,\n",
       "       4.01600e+01, 7.33700e+01, 1.76300e+01, 2.15500e+01, 1.53000e+01,\n",
       "       2.34300e+01, 2.31100e+01, 3.01389e+03, 1.50000e+01, 2.15100e+01,\n",
       "       3.62900e+01, 3.29900e+01, 2.77600e+01, 2.47600e+01, 2.48100e+01,\n",
       "       2.23900e+01, 3.23200e+01, 3.95000e+00, 2.67000e+01, 2.56600e+01,\n",
       "       2.16200e+01, 2.33000e+01, 2.24200e+01, 2.10000e+01, 2.31400e+01,\n",
       "       1.98200e+01, 1.83100e+01, 2.05300e+01, 3.87000e+00, 2.11000e+01,\n",
       "       4.21600e+01, 1.89000e+01, 2.39200e+01, 4.46400e+01, 1.51200e+01,\n",
       "       1.68300e+01, 1.55500e+01, 2.91400e+01, 2.65200e+01, 2.37700e+01,\n",
       "       2.93800e+01, 1.58200e+01, 2.79800e+01, 2.36200e+01, 3.02700e+01,\n",
       "       2.07700e+01, 2.52000e+01, 3.65800e+01, 2.40200e+01, 2.86600e+01,\n",
       "       2.50000e+01, 2.38800e+01, 2.24900e+01, 2.48300e+01, 2.77700e+01,\n",
       "       2.53200e+01, 2.71800e+01, 2.28700e+01, 2.19800e+01, 2.54000e+01,\n",
       "       3.00500e+01, 3.69800e+01, 2.59500e+01, 2.65000e+01, 3.50200e+01,\n",
       "       2.72800e+01, 2.52500e+01, 2.63400e+01, 2.98000e+01, 3.44800e+01,\n",
       "       3.35300e+01, 2.41100e+01, 2.11600e+01, 2.96500e+01, 2.14100e+01,\n",
       "       1.85400e+01, 2.18700e+01, 2.46900e+01, 2.21500e+01, 2.14700e+01,\n",
       "       2.17500e+01, 2.35600e+01, 2.12200e+01, 1.96100e+01, 2.00900e+01,\n",
       "       2.45700e+01, 2.74600e+01, 2.57500e+01, 2.29500e+01, 2.08500e+01,\n",
       "       2.17700e+01, 2.66100e+01, 3.10000e+00, 3.10700e+01, 3.19300e+01,\n",
       "       1.68900e+01, 3.49500e+01, 2.43900e+01, 3.26100e+01, 2.73000e+01,\n",
       "       2.30500e+01, 2.76700e+01, 2.46200e+01, 2.63700e+01, 1.95800e+01,\n",
       "       2.71600e+01, 3.00600e+01, 1.93700e+01, 2.66000e+01, 3.59601e+03,\n",
       "       1.98500e+01, 2.81900e+01, 2.35800e+01, 2.41900e+01, 2.74000e+01,\n",
       "       2.90700e+01, 1.77800e+01, 1.67900e+01, 1.87300e+01, 2.59600e+01,\n",
       "       1.59900e+01, 1.59800e+01, 2.64000e+01, 1.95400e+01, 1.85900e+01])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_8.iloc[:,-1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_9 = remove_rows_where_column_larger_than(X_8,'bmi',40)\n",
    "X_10 = remove_rows_where_column_lower_than(X_9,'bmi',16)\n",
    "X = X_10.iloc[:,:-1]; y = X_10.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malth\\AppData\\Local\\Temp\\ipykernel_15044\\3960294132.py:6: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  X_4.iloc[:,-1] = X_4.iloc[:,-1].astype('float')\n"
     ]
    }
   ],
   "source": [
    "X_0 = pd.concat([pd.DataFrame(true_preprocessing.X),true_preprocessing.meta_data['bmi'],true_preprocessing.meta_data['country']],axis=1)\n",
    "X_1 = remove_rows_where_column_nan(X_0,'bmi')\n",
    "X_2 = remove_rows_where_column_specified(X_1,'bmi','Unspecified','bmi','other','bmi','unknown')\n",
    "X_3 = keep_rows_where_column_specified(X_2,'country','United Kingdom')\n",
    "X_4 = X_3.iloc[:,:-1]\n",
    "X_4.iloc[:,-1] = X_4.iloc[:,-1].astype('float')\n",
    "X_5 = remove_rows_where_column_larger_than(X_4,'bmi',40)\n",
    "X_6 = remove_rows_where_column_lower_than(X_5,'bmi',16)\n",
    "X = X_6.iloc[:,:-1]; y = X_6.iloc[:,-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 47.69it/s]\n"
     ]
    }
   ],
   "source": [
    "ref_scores = []\n",
    "for i in tqdm(range(20)):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "    dummy = DummyRegressor(strategy=\"mean\")\n",
    "    ref_scores.append(np.mean(cross_val_score(dummy, X.iloc[:,1:], y, scoring=scorer, cv=kf)))\n",
    "    #print(\"Reference score: {}\".format(np.mean(ref_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  3.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "svm_scores = []\n",
    "for i in tqdm(range(20)):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "    svm_model = SVR(kernel = 'rbf', C=1.0, epsilon=0.1)\n",
    "    svm_scores.append(np.mean(cross_val_score(svm_model, X.iloc[:,1:], y, scoring=scorer, cv=kf, n_jobs=-1)))\n",
    "    #print(\"SVM score: {}\".format(np.mean(svm_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  6.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso \n",
    "\n",
    "lasso_scores = []\n",
    "for i in tqdm(range(20)):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "    lasso_model = Lasso()\n",
    "    lasso_scores.append(np.mean(cross_val_score(lasso_model, X.iloc[:,1:], y, scoring=scorer, cv=kf, n_jobs=-1)))\n",
    "    #print(\"Linear Regression with L1 score: {}\".format(np.mean(lasso_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [23:09<00:00, 69.46s/it]\n"
     ]
    }
   ],
   "source": [
    "# random forest performance\n",
    "rf_scores = []\n",
    "for i in tqdm(range(20)):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "    rf_model = RandomForestRegressor(500)\n",
    "    rf_scores.append(np.mean(cross_val_score(rf_model, X.iloc[:,1:], y, scoring=scorer, cv=kf, n_jobs=-1)))\n",
    "    #print(\"Random forest score: {}\".format(np.mean(rf_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malth\\AppData\\Local\\Temp\\ipykernel_15044\\1988036143.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  X_tmp.columns = X_tmp.columns.str.replace('[','_')\n",
      "C:\\Users\\malth\\AppData\\Local\\Temp\\ipykernel_15044\\1988036143.py:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  X_tmp.columns = X_tmp.columns.str.replace(']','_')\n"
     ]
    }
   ],
   "source": [
    "X_tmp = X\n",
    "X_tmp.columns = X_tmp.columns.str.replace('[','_')\n",
    "X_tmp.columns = X_tmp.columns.str.replace(']','_')\n",
    "X_tmp.columns = X_tmp.columns.str.replace('<','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:33<00:00,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Regressor score: 16.128018419841545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost performance\n",
    "XGB_scores = []\n",
    "for i in tqdm(range(20)):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "    XGB_model = XGBRegressor(colsample_bytree=0.66,learning_rate=0.15, max_depth=2, \n",
    "                        reg_lambda=1, n_estimators=500, objective='reg:squarederror')\n",
    "    XGB_scores.append(np.mean(cross_val_score(XGB_model, X_tmp.iloc[:,1:], y, scoring=scorer, cv=kf, n_jobs=-1)))\n",
    "#print(\"XGBoost Regressor score: {}\".format(np.mean(XGB_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Regressor score: 16.128018419841545\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBoost Regressor score: {}\".format(np.mean(XGB_scores)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=17.441, est=16.729, cfg={'C': 100, 'gamma': 0.001}\n",
      ">acc=17.392, est=17.802, cfg={'C': 100, 'gamma': 0.001}\n",
      ">acc=18.047, est=16.764, cfg={'C': 100, 'gamma': 0.001}\n",
      ">acc=19.723, est=16.071, cfg={'C': 100, 'gamma': 0.001}\n",
      ">acc=15.166, est=17.989, cfg={'C': 100, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "svm_scores, svm_params = SVM_CV(X.iloc[:,1:],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=18.680, est=18.676, cfg={'alpha': 0.0001}\n",
      ">acc=17.462, est=19.600, cfg={'alpha': 0.0001}\n",
      ">acc=18.579, est=18.758, cfg={'alpha': 0.0001}\n",
      ">acc=20.877, est=19.179, cfg={'alpha': 0.0001}\n",
      ">acc=15.170, est=20.927, cfg={'alpha': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "logistic_scores, logistic_params = logistic_CV(X.iloc[:,1:],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores, rf_params = rf_CV(X.iloc[:,1:],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_scores, XGB_params = XGB_CV(X.iloc[:,1:],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_scores = dummy_CV(X.iloc[:,1:],y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression statistic=60 and p-value=0.0973\n",
      "Lasso mean=16 and ref mean=15.6452\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "print('Logistic Regression statistic=%.0f and p-value=%.4f' % (wilcoxon(lasso_scores,ref_scores, alternative='two-sided')))\n",
    "print('Lasso mean=%.0f and ref mean=%.4f' % (np.mean(lasso_scores), np.mean(ref_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [ref_scores, svm_scores, lasso_scores, rf_scores, XGB_scores]\n",
    "labels = ['Dummy', 'SVM', 'Linear', 'rf', 'XGB']\n",
    "\n",
    "plt.boxplot(data, labels=labels)\n",
    "plt.ylim(14.4,16.7)\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Method')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenvyaml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72597f99bc2163ae545466629695ca805d41b2440924b75a489a65d0a29c0e42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
